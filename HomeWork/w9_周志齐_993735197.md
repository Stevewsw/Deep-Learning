# 第九周作业

## 数据准备

Tinymind上数据集地址为: https://www.tinymind.com/zhouzhiqi/datasets/quiz-w8-data

![1525156357293](C:\Users\zhouz\AppData\Local\Temp\1525156357293.png)

## 模型正常运行

Tinymind上模型运行结果为: https://www.tinymind.com/executions/p3znbsqj
随机截取部分输出日志:
```
INFO:tensorflow:global step 491: loss = 2.4809 (0.306 sec/step)
INFO:tensorflow:global step 492: loss = 2.8503 (0.315 sec/step)
INFO:tensorflow:global step 493: loss = 2.6786 (0.357 sec/step)
INFO:tensorflow:global step 494: loss = 3.0032 (0.353 sec/step)
INFO:tensorflow:global step 495: loss = 2.9489 (0.295 sec/step)
INFO:tensorflow:global step 496: loss = 2.8251 (0.348 sec/step)
INFO:tensorflow:global step 497: loss = 2.8868 (0.342 sec/step)
INFO:tensorflow:global step 498: loss = 2.8214 (0.300 sec/step)
INFO:tensorflow:global step 499: loss = 2.9244 (0.354 sec/step)
INFO:tensorflow:global step 500: loss = 2.5837 (0.301 sec/step)
INFO:tensorflow:Stopping Training.
INFO:tensorflow:Finished training! Saving model to disk.
```

## 输出结果
Tinymind上运行的output地址为: https://www.tinymind.com/executions/p3znbsqj/output

output.png为: 

![output.png](https://storage.googleapis.com/tinymind/execs/p3znbsqj/output/output.png?GoogleAccessId=production%40colafly-tinymind.iam.gserviceaccount.com&Expires=1525185303&Signature=SsFNTDV9jwur3jZ9%2Bp%2Ba1ShdH5Tv%2B6wNATFCqwWHOJyQwxQnPMJPDifkkmIJzmtx2Fwo66MdoESedCerrVdiQL0jhY1t9oOfT1XCycBwH43g%2FgOvjcIc1Je22cJBcMSsIlWY90BfRXxfbS1sLmoRnSAm1PBT%2F737Xp2W9WDj9ab%2BKzz6B4RUko6WlAz5h8vnj7JmczSqRdVpLNr4mkns1T0QjoDGELEC7MVMRh4OEqBuV7FcjVsqoyrGYaaxOlr6rwhe91uK0%2F5hk4ZukKv8tDX6J1rFwV%2FcyBWsa7ZENfxP2QtkoNdCzaTzbWvcGDAs2z399N69aiWRxvhuMAiJjA%3D%3D)



# 填坑日记

## 指定目录

python ./object_detection/train.py --train_dir=data/zhouzhiqi/quiz-w8-data/train --pipeline_config_path=ssd_mobilenet_v1_pets.config 

当前文件夹下
正确: --dataset_dir=data/quiz-w8-data
错误: --dataset_dir=/data/quiz-w8-data

## protoc

linux 安装protobuf,以及python版

1.下载安装包
portobuf的官网下载地址是点击打开链接: https://github.com/google/protobuf/releases，选择的版本是protobuf-all-3.5.0.tar.gz
2.解压、编译、安装

```
tar -xf  protobuf-all-3.5.0.tar.gz
cd protobuf-3.5.0
./configure
make 
make check
make install
```

3.继续安装protobuf的python模块（不需要python的，不需要安装）

```
cd ./python 
python setup.py build 
python setup.py test 
python setup.py install 
```

4.验证是否安装成功（查看安装的protobuf版本号）

```
protoc --version 
```

5.验证python模块有没有被正确安装

```
#python   
>>>import google.protobuf 
```

如果没有报错，说明安装正常

## 导入自定义模块

直接将模块放入: 安装位置/anaconda3/lib/python3.5/site-packages目录下

或者直接在train.py中加入添加路径的代码:

```python
import sys
print(os.getcwd())
path = os.path.join(os.getcwd(), 'slim')
sys.path.append(os.getcwd())
sys.path.append(path)
```



## 运行

## A - pycocotools

> 代码: python ./object_detection/eval.py
> 异常: ImportError: No module named 'pycocotools'
> 解决方法: 
> Microsoft COCO 是 一个标注过的图片数据集，可用以目标检测、分割和描述生成等. 
> Pycocotools 是 python api tools of coco...
>
> 1. 获取源码
>
> ```
> git clone https://github.com/pdollar/coco.git
> ```
>
> 
>
> 1. 编译
>
> ```
> cd coco/PythonAPI
> install pycocotools locally
> python setup.py build_ext --inplace
> install pycocotools to the Python site-packages
> python setup.py build_ext install
> ```
>
> 



## B

> 代码: python ./object_detection/train.py
> 异常: TypeError: `pred` must be a Tensor, a Variable, or a Python bool.
> 解决方法:
> 搜素并打开 ssd_mobilenet_v1_feature_extractor.py
> 定位到 107到109行, 把 is_training=None改成 is_training=True即可 ，如下
> with slim.arg_scope(
> mobilenet_v1.mobilenet_v1_arg_scope(
> is_training=True, regularize_depthwise=True)):
> tf1.4对None的支持不友好

## C

> 代码:  python ./object_detection/train.py
> 异常: 'tensorflow.contrib.data' has no attribute 'parallel_interleave'
> 解决方法:
> 搜素并打开 dataset_util.py
> 定位到 132到135行, 把tf.contrib.data.parallel_interleave
> 改为tf.contrib.data.sloppy_interleave, 并删除sloppy=True, 如下
> tf.contrib.data.sloppy_interleave(
> file_read_func, 
> cycle_length=config.num_readers,
> block_length=config.read_block_length,))# sloppy=True))



## D

代码: python ./object_detection/train.py 异常: ValueError: axis = 0 not in [0, 0) 解决方法:

```
loss {
classification_loss {
weighted_sigmoid {
}
}
localization_loss {
weighted_smooth_l1 {
}
}
hard_example_miner {
num_hard_examples: 3000
iou_threshold: 0.99
loss_type: CLASSIFICATION
max_negatives_per_positive: 3
min_negatives_per_image: 0
}
classification_weight: 1.0
localization_weight: 1.0
}
to

loss {
classification_loss {
weighted_sigmoid {
anchorwise_output: true #add this
}
}
localization_loss {
weighted_smooth_l1 {
anchorwise_output: true #add this
}
}
hard_example_miner {
num_hard_examples: 3000
iou_threshold: 0.99
loss_type: CLASSIFICATION
max_negatives_per_positive: 3
min_negatives_per_image: 0
}
classification_weight: 1.0
localization_weight: 1.0
}
```